{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94292dde",
   "metadata": {},
   "source": [
    "# The 5 Assumptions of Linear Regression\n",
    "\n",
    "These are the conditions that must be met for the results of a regression analysis to be valid and reliable. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e06b5",
   "metadata": {},
   "source": [
    "##### 1. Linearity \n",
    "- The relationship between the independent and dependent variables is linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35e514",
   "metadata": {},
   "source": [
    "##### 2. No Multicollinearity \n",
    "- Multicollinearity is observed when two or more independent variables have a high correlation between each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36a620",
   "metadata": {},
   "source": [
    "##### 3. No Endogeneity of Regressors\n",
    "- Endogeneity refers to situations in which an independent variable in a linear regression model is correlated to the error term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cadf11",
   "metadata": {},
   "source": [
    "##### 4. Normality and Homoscedasticity of the error term \n",
    "- Normality means the error term is normally distributed. The expected value of the error is zero as we expect to have no errors on average. \n",
    "- Homoscedasticity in plain English means constant variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8fa19d",
   "metadata": {},
   "source": [
    "##### 5. No Autocorrelation \n",
    "- Mathematically, the covariance of any two error terms is zero. That's the assumption that would usually stop you from using a linear regression in your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3828d9",
   "metadata": {},
   "source": [
    "## How to test\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d19a13",
   "metadata": {},
   "source": [
    "### 1. Linearity - Use a scatter plot \n",
    "\n",
    "Plot each independent variable against the dependent variable. A clear linear relationship will appear as a straight line or a tight cluster of points around a straight line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5eb2c6",
   "metadata": {},
   "source": [
    "- If the data points form a pattern that looks like a straight line, then a linear regression model is suitable.\n",
    "- If the relationship is non-linear, you should not use the data before transforming it appropriately eather a Log or Exponential transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f543b7",
   "metadata": {},
   "source": [
    "### 2. No Multicollinearity - Use Variance Inflation Factor (VIF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea99e3",
   "metadata": {},
   "source": [
    "- VIF = 1: no multicollinearity\n",
    "- 1 < VIF < 5: perfectly okay\n",
    "- 5 to 10 < VIF: unacceptable\n",
    "\n",
    "- If there is multicollinearity then this imposes a big problem to the regression model as the coefficients will be wrongly estimated. The reasoning is that, if A can be represented using B, there is no point using both \n",
    "\n",
    "Fix: 1. Drop one of the two variables. 2. Transform them into one variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e850c",
   "metadata": {},
   "source": [
    "### 3. No Endogeneity - Durbin-Wu-Hausman (DWH) Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80a782",
   "metadata": {},
   "source": [
    "A variable is endogenous if it’s linked with the information that is not included or can’t be measured in the model.\n",
    "\n",
    "Cause & Example\n",
    "1. Omitted Variable\t- You forgot to include “weather front strength,” which affects both humidity and temperature\n",
    "2. Reverse Causality - Higher temperature itself changes humidity\n",
    "3. Measurement Error - The humidity sensor is noisy, so the “error” spills into \n",
    "\n",
    "- If any of these happen → endogeneity problem → OLS is biased & need to run\n",
    "- If not → your model is fine with OLS and can use the independent variables where p value < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb13646",
   "metadata": {},
   "source": [
    "The Hausman test compares:\n",
    "- OLS (ordinary least squares, consistent but potentially biased)\n",
    "- IV/2SLS (instrumental variables, consistent if instruments are valid)\n",
    "\n",
    "If there’s a significant difference, OLS is likely biased → endogeneity is present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13544b",
   "metadata": {},
   "source": [
    "1. Perform OLS and 2SLS regressions:\n",
    "- Run the original regression using Ordinary Least Squares (OLS) to get the OLS coefficients.\n",
    "- Perform a Two-Stage Least Squares (2SLS) regression using the same model but including the instrumental variable(s).\n",
    "2. Compare the coefficients: Compare the coefficients for the suspected endogenous variable from both the OLS and 2SLS regressions.\n",
    "T3. est for significance: If the coefficients differ significantly, it indicates endogeneity. The DWH test formally compares these coefficients. A statistically significant difference suggests the OLS results are biased and the 2SLS results are more appropriate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2dfb6a",
   "metadata": {},
   "source": [
    "### 4. Normality and Homoscedasticity - Test after predictions with a Histogram and Scatter plot\n",
    "\n",
    "Normality - Histogram: Create a histogram of the residuals (calculated as the difference between the actual value and the predicted value for each data point (y-^y)). A normal distribution should resemble a bell curve, if the histogram is heavily skewed or has multiple peaks, it may violate the assumption of normality.\n",
    "\n",
    "Homoscedasticity - Scatter plot: Residuals should roughly be centered around 0 with no clear pattern — this indicates the model errors are random, a good sign for linear regression assumptions.\n",
    "- If points are randomly scattered → good, homoscedastic.\n",
    "- If residuals fan out or form a pattern → heteroscedasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b30a1",
   "metadata": {},
   "source": [
    "If there is heteroscedasticity (huge variance) calculate the naturl log\n",
    "- Semi-log model -  as X increases by one unit, Y changes, by b1 percent.\n",
    "- Log-log model - for each percentage point change in x, Y changes by b1 percentage points. Graph shrinks in height and width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396de7b",
   "metadata": {},
   "source": [
    "### 5. No Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31e25c",
   "metadata": {},
   "source": [
    "To check for this: plot all the residuals on a graph and look for patterns. If you can't find any, you're safe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77adb4",
   "metadata": {},
   "source": [
    "Another way is the Durbin Watson test - 0 - 4. 2 indicates no autocorrelation while values below 1 and above 3 cause for alarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a827df7",
   "metadata": {},
   "source": [
    "- The Durbin-Watson statistic ranges from 0 to 4:\n",
    "\n",
    "    - Results 2: Indicates no autocorrelation.\n",
    "    - Results 0 to <2: Indicates positive autocorrelation.\n",
    "    - Results > 2 to 4: Indicates negative autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f1e0a",
   "metadata": {},
   "source": [
    "- Do not use the linear regression model when error terms are autocorrelated (like time series data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b3eb0",
   "metadata": {},
   "source": [
    "# Overfitting & Underfitting - problem encompassing predictive analytics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494773d",
   "metadata": {},
   "source": [
    "##### Overfitting: \n",
    " - Means the regression has focused on the particular dataset so much it has \"missed the point.\" When a model captures noise in the data and is too complex. It will perform exceptionally well on training data but poorly on unseen data.\n",
    "    - Line follows the data points too close\n",
    "    - Misses the point\n",
    "    - High train accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40c2d1",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "- Split the initial dataset into training and test data 90/10 or 80/20 \n",
    "- Create the regression on the training data - then test the model on the test data by creating a confusion matrix and assessing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af901fd1",
   "metadata": {},
   "source": [
    "##### Underfitting: \n",
    "- Means the model has not captured the underlying logic of the data. It doesn't know what to do and therefore provides an answer that is far from correct. When a model is too simple to capture the underlying trends in the data, resulting in poor performance on both the training and testing sets. Poor predictive power & low accuracy\n",
    "    - Line does not follow the data points\n",
    "    - Doesnt capture any logic\n",
    "    - Low train accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19caa56",
   "metadata": {},
   "source": [
    "##### A good model:\n",
    "- Captures the underlying logic of the dataset\n",
    "- High train accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
