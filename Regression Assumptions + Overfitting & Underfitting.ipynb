{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94292dde",
   "metadata": {},
   "source": [
    "# The 5 Regression Assumptions \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e06b5",
   "metadata": {},
   "source": [
    "##### 1. Linearity \n",
    "- linear regression is the simplest one and assumes linearity. Each independent variable is multiplied by a coefficient and summed up to predict the value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36a620",
   "metadata": {},
   "source": [
    "##### 2. Endogeneity of Regressors\n",
    "- Mathematically, this is expressed as the covariance of the error, and the Xs is 0 for any error or X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cadf11",
   "metadata": {},
   "source": [
    "##### 3. Normality and Homoscedasticity of the error term \n",
    "- Normality means the error term is normally distributed. The expected value of the error is zero as we expect to have no errors on average. Homoscedasticity in plain English means constant variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8fa19d",
   "metadata": {},
   "source": [
    "##### 4. No Autocorrelation \n",
    "- Mathematically, the covariance of any two error terms is zero. That's the assumption that would usually stop you from using a linear regression in your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35e514",
   "metadata": {},
   "source": [
    "##### 5. No Multicollinearity \n",
    "- Multicollinearity is observed when two or more variables have a high correlation between each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d19a13",
   "metadata": {},
   "source": [
    "## 1. Linearity - use a scatter plot (only for Linear Regression)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15394528",
   "metadata": {},
   "source": [
    "A linear regression is the simplest non-trivial relationship. It is called linear because the equation is linear. Each independent variable is multiplied by a coefficient, and summed up to predict the value of the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5eb2c6",
   "metadata": {},
   "source": [
    "- The easiest way is to choose an independent variable x1, and plot it against the dependent y on a scatter plot. If the data points form a pattern that looks like a straight line, then a linear regression model is suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544938e8",
   "metadata": {},
   "source": [
    "- If the relationship is non-linear, you should not use the data before transforming it appropriately eather a Log or Exponential transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e850c",
   "metadata": {},
   "source": [
    "## 2. No Endogeneity - where p value < 0.05\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e3493b",
   "metadata": {},
   "source": [
    "Refers to the prohibition of a link between the independent variables and the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea85f7ca",
   "metadata": {},
   "source": [
    "- Omitted variable bias is introduced to the model when you forget to include a relevant variable. As each independent variable explains y, they move together and are somewhat correlated. Similarly, y is also explained by the omitted variable, so they are also correlated. Chances are, the omitted variable is also correlated with at least one independent x. However, you forgot to include it as a regressor. Everything that you don't explain with your model goes into the error. So actually, the error becomes correlated with everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a53fd",
   "metadata": {},
   "source": [
    "- An incorrect exclusion of a variable, like in this case, leads to biased and counterintuitive estimates that are toxic to your regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d7bf0c",
   "metadata": {},
   "source": [
    "- An incorrect inclusion of a variable, as we saw in our \"Adjusted R-squared\" lecture, leads to inefficient estimates, which don't bias the regression, and you can immediately drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2dfb6a",
   "metadata": {},
   "source": [
    "## 3. Normality and Homoscedasticity\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5648549",
   "metadata": {},
   "source": [
    "Normality - assume the error term is normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78714b28",
   "metadata": {},
   "source": [
    "Zero Mean - if the mean is not expected to be zero, then the line is not the best fitting one. Having an intercept solves that problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b30a1",
   "metadata": {},
   "source": [
    "Homoscedasticity - to have equal variance. The error term should have equal variance, one with the other. If there is heteroscedasticity (huge variance) the you can calculate the naturl log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf60b37",
   "metadata": {},
   "source": [
    "- Semi-log model -  as X increases by one unit, Y changes, by b1 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e9c8a",
   "metadata": {},
   "source": [
    "- Log-log model - for each percentage point change in x, Y changes by b1 percentage points. Graph shrinks in height and width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396de7b",
   "metadata": {},
   "source": [
    "## 4. No Autocorrelation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b2afd",
   "metadata": {},
   "source": [
    "Errors are assumed to be uncorrelated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31e25c",
   "metadata": {},
   "source": [
    "To check for this: plot all the residuals on a graph and look for patterns. If you can't find any, you're safe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77adb4",
   "metadata": {},
   "source": [
    "Another way is the Durbin Watson test - 0 - 4. 2 indicates no autocorrelation while values below 1 and above 3 cause for alarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f1e0a",
   "metadata": {},
   "source": [
    "- Do not use the linear regression model when error terms are autocorrelated (like time series data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a827df7",
   "metadata": {},
   "source": [
    "- The Durbin-Watson statistic ranges from 0 to 4:\n",
    "\n",
    "    - Results 2: Indicates no autocorrelation.\n",
    "    - Results 0 to <2: Indicates positive autocorrelation.\n",
    "    - Results > 2 to 4: Indicates negative autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f543b7",
   "metadata": {},
   "source": [
    "## 5. No Multicollinearity\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162402e",
   "metadata": {},
   "source": [
    "We observe multicollinearity when two or more variables have a high correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea99e3",
   "metadata": {},
   "source": [
    "- If there is multicollinearity then this imposes a big problem to our regression model as the coefficients will be wrongly estimated. The reasoning is that, if A can be represented using B, there is no point using both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce2993",
   "metadata": {},
   "source": [
    "- VIF = 1: no multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc4351",
   "metadata": {},
   "source": [
    "- 1 < VIF < 5: perfectly okay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be162c0",
   "metadata": {},
   "source": [
    "- 5 to 10 < VIF: unacceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e297c9e8",
   "metadata": {},
   "source": [
    "Fix: 1. Drop one of the two variables. 2. Transform them into one variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b3eb0",
   "metadata": {},
   "source": [
    "# Overfitting & Underfitting - problem encompassing predictive analytics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494773d",
   "metadata": {},
   "source": [
    "##### Overfitting: \n",
    " - Means the regression has focused on the particular dataset so much it has \"missed the point.\" When a model captures noise in the data and is too complex. It will perform exceptionally well on training data but poorly on unseen data.\n",
    "    - Line follows the data points too close\n",
    "    - Misses the point\n",
    "    - High train accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40c2d1",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "- Split the initial dataset into training and test data 90/10 or 80/20 \n",
    "- Create the regression on the training data - then test the model on the test data by creating a confusion matrix and assessing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af901fd1",
   "metadata": {},
   "source": [
    "##### Underfitting: \n",
    "- Means the model has not captured the underlying logic of the data. It doesn't know what to do and therefore provides an answer that is far from correct. When a model is too simple to capture the underlying trends in the data, resulting in poor performance on both the training and testing sets. Poor predictive power & low accuracy\n",
    "    - Line does not follow the data points\n",
    "    - Doesnt capture any logic\n",
    "    - Low train accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19caa56",
   "metadata": {},
   "source": [
    "##### A good model:\n",
    "- Captures the underlying logic of the dataset\n",
    "- High train accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
